{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suburb              0\n",
      "Address             0\n",
      "Rooms               0\n",
      "Type                0\n",
      "Price               0\n",
      "Method              0\n",
      "SellerG             0\n",
      "Date                0\n",
      "Distance            0\n",
      "Postcode            0\n",
      "Bedroom2            0\n",
      "Bathroom            0\n",
      "Car                62\n",
      "Landsize            0\n",
      "BuildingArea     6450\n",
      "YearBuilt        5375\n",
      "CouncilArea      1369\n",
      "Lattitude           0\n",
      "Longtitude          0\n",
      "Regionname          0\n",
      "Propertycount       0\n",
      "dtype: int64\n",
      "Total number of rows: 13580\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the raw dataset\n",
    "file_path = '/Users/mac/Desktop/Computing Innovation Project/Melbourne_DataSet/melb_data.csv'\n",
    "sales_data = pd.read_csv(file_path)\n",
    "\n",
    "#Identify missing value\n",
    "missing_values = sales_data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "#Count the total row\n",
    "row_count = len(sales_data)\n",
    "print(f'Total number of rows: {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landsize 0.0 values : 1939\n"
     ]
    }
   ],
   "source": [
    "#Identify How many Landsize that value 0.0\n",
    "zero_landsize_count = (sales_data['Landsize'] == 0).sum()\n",
    "print(f\"Landsize 0.0 values : {zero_landsize_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes on 0.0 values with median\n",
    "median_landsize = sales_data['Landsize'][sales_data['Landsize'] > 0.0].median()\n",
    "sales_data['Landsize'] = sales_data['Landsize'].replace(0.0, median_landsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landsize 0.0 values : 0\n"
     ]
    }
   ],
   "source": [
    "# Result after changes \n",
    "zero_landsize_count = (sales_data['Landsize'] == 0).sum()\n",
    "print(f\"Landsize 0.0 values : {zero_landsize_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Price       Landsize\n",
      "count  1.358000e+04   13580.000000\n",
      "mean   1.075684e+06     634.519735\n",
      "std    6.393107e+05    3984.371192\n",
      "min    8.500000e+04       1.000000\n",
      "25%    6.500000e+05     305.000000\n",
      "50%    9.030000e+05     533.000000\n",
      "75%    1.330000e+06     651.000000\n",
      "max    9.000000e+06  433014.000000\n"
     ]
    }
   ],
   "source": [
    "print(sales_data[['Price', 'Landsize']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the name to avoid duplication when checking for summary between Orignal Attribute and Winsorized Attribute\n",
    "sales_data['Landsize_original'] = sales_data['Landsize']\n",
    "sales_data['Price_original'] = sales_data['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying winsorization method to deal with extreme value on both upper and lower by 1%\n",
    "\n",
    "from scipy.stats import mstats\n",
    "sales_data['Landsize_winsorized'] = mstats.winsorize(sales_data['Landsize_original'], limits=[0.01, 0.01])\n",
    "sales_data['Price_winsorized'] = mstats.winsorize(sales_data['Price_original'], limits=[0.01, 0.01])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Landsize:\n",
      "count     13580.000000\n",
      "mean        634.519735\n",
      "std        3984.371192\n",
      "min           1.000000\n",
      "25%         305.000000\n",
      "50%         533.000000\n",
      "75%         651.000000\n",
      "max      433014.000000\n",
      "Name: Landsize, dtype: float64\n",
      "Winsorized Landsize:\n",
      "count    13580.000000\n",
      "mean       543.292268\n",
      "std        389.378717\n",
      "min         77.000000\n",
      "25%        305.000000\n",
      "50%        533.000000\n",
      "75%        651.000000\n",
      "max       2978.000000\n",
      "Name: Landsize_winsorized, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:4809: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n"
     ]
    }
   ],
   "source": [
    "# Check summary statistics for original and winsorized Landsize \n",
    "print(\"Original Landsize:\")\n",
    "print(sales_data['Landsize'].describe())\n",
    "\n",
    "print(\"Winsorized Landsize:\")\n",
    "print(sales_data['Landsize_winsorized'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Price:\n",
      "count    1.358000e+04\n",
      "mean     1.075684e+06\n",
      "std      6.393107e+05\n",
      "min      8.500000e+04\n",
      "25%      6.500000e+05\n",
      "50%      9.030000e+05\n",
      "75%      1.330000e+06\n",
      "max      9.000000e+06\n",
      "Name: Price, dtype: float64\n",
      "Winsorized Price:\n",
      "count    1.358000e+04\n",
      "mean     1.067724e+06\n",
      "std      5.952652e+05\n",
      "min      3.000000e+05\n",
      "25%      6.500000e+05\n",
      "50%      9.030000e+05\n",
      "75%      1.330000e+06\n",
      "max      3.350000e+06\n",
      "Name: Price_winsorized, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:4809: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n"
     ]
    }
   ],
   "source": [
    "# Check summary statistics for original and winsorized Price\n",
    "print(\"Original Price:\")\n",
    "print(sales_data['Price'].describe())\n",
    "\n",
    "print(\"Winsorized Price:\")\n",
    "print(sales_data['Price_winsorized'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number capped at lower limit for Landsize: 137\n",
      "Number capped at upper limit for Landsize: 0\n",
      "Number capped at lower limit for Price: 151\n",
      "Number capped at upper limit for Price: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking How many value have been capped on Landsize and Price\n",
    "\n",
    "#the percentile limits\n",
    "lower_limit_landsize = sales_data['Landsize_original'].quantile(0.01)\n",
    "upper_limit_landsize = sales_data['Landsize_original'].quantile(0.99)\n",
    "\n",
    "lower_limit_price = sales_data['Price_original'].quantile(0.01)\n",
    "upper_limit_price = sales_data['Price_original'].quantile(0.99)\n",
    "\n",
    "#Count how many values were capped at the lower and upper limits for Landsize\n",
    "lower_capped_landsize = (sales_data['Landsize_winsorized'] == lower_limit_landsize).sum()\n",
    "upper_capped_landsize = (sales_data['Landsize_winsorized'] == upper_limit_landsize).sum()\n",
    "\n",
    "#Count how many values were capped at the lower and upper limits for Price\n",
    "lower_capped_price = (sales_data['Price_winsorized'] == lower_limit_price).sum()\n",
    "upper_capped_price = (sales_data['Price_winsorized'] == upper_limit_price).sum()\n",
    "\n",
    "\n",
    "print(f\"Number capped at lower limit for Landsize: {lower_capped_landsize}\")\n",
    "print(f\"Number capped at upper limit for Landsize: {upper_capped_landsize}\")\n",
    "\n",
    "print(f\"Number capped at lower limit for Price: {lower_capped_price}\")\n",
    "print(f\"Number capped at upper limit for Price: {upper_capped_price}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/93nzx6zn4qq3tmg26cwcn91w0000gn/T/ipykernel_6622/245257546.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sales_data['CouncilArea'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Replace missing value of CouncilArea with the word \"Unknown\"\n",
    "\n",
    "sales_data['CouncilArea'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Unnecessary Data\n",
    "sales_data.drop(columns=['Car'], inplace=True)\n",
    "sales_data.drop(columns=['SellerG'], inplace=True)\n",
    "sales_data.drop(columns=['YearBuilt'], inplace=True)\n",
    "sales_data.drop(columns=['BuildingArea'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suburb                 0\n",
      "Address                0\n",
      "Rooms                  0\n",
      "Type                   0\n",
      "Price                  0\n",
      "Method                 0\n",
      "Date                   0\n",
      "Distance               0\n",
      "Postcode               0\n",
      "Bedroom2               0\n",
      "Bathroom               0\n",
      "Landsize               0\n",
      "CouncilArea            0\n",
      "Lattitude              0\n",
      "Longtitude             0\n",
      "Regionname             0\n",
      "Propertycount          0\n",
      "Landsize_original      0\n",
      "Price_original         0\n",
      "Landsize_winsorized    0\n",
      "Price_winsorized       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Identify missing value again to check if there are null value after cleaning\n",
    "missing_values = sales_data.isnull().sum()\n",
    "\n",
    "print(missing_values)\n",
    "\n",
    "row_count = len(sales_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Type\n",
      "0  house\n",
      "1  house\n",
      "2  house\n",
      "3  house\n",
      "4  house\n",
      "5  house\n",
      "6  house\n",
      "7  house\n",
      "8   unit\n",
      "9  house\n"
     ]
    }
   ],
   "source": [
    "# replace the word of Type to meaningful name\n",
    "sales_data['Type'] = sales_data['Type'].replace({\n",
    "    'h': 'house',\n",
    "    'u': 'unit',\n",
    "    't': 'townhouse'\n",
    "})\n",
    "\n",
    "print(sales_data[['Type']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Suburb           Address  Rooms   Type      Price Method       Date  \\\n",
      "0  Abbotsford      85 Turner St      2  house  1480000.0      S  3/12/2016   \n",
      "1  Abbotsford   25 Bloomburg St      2  house  1035000.0      S  4/02/2016   \n",
      "2  Abbotsford      5 Charles St      3  house  1465000.0     SP  4/03/2017   \n",
      "3  Abbotsford  40 Federation La      3  house   850000.0     PI  4/03/2017   \n",
      "4  Abbotsford       55a Park St      4  house  1600000.0     VB  4/06/2016   \n",
      "\n",
      "   Distance from CBD  Postcode  Bedroom2  ...  Landsize  CouncilArea  \\\n",
      "0                2.5    3067.0       2.0  ...     202.0        Yarra   \n",
      "1                2.5    3067.0       2.0  ...     156.0        Yarra   \n",
      "2                2.5    3067.0       3.0  ...     134.0        Yarra   \n",
      "3                2.5    3067.0       3.0  ...      94.0        Yarra   \n",
      "4                2.5    3067.0       3.0  ...     120.0        Yarra   \n",
      "\n",
      "  Lattitude  Longtitude             Regionname Propertycount  \\\n",
      "0  -37.7996    144.9984  Northern Metropolitan        4019.0   \n",
      "1  -37.8079    144.9934  Northern Metropolitan        4019.0   \n",
      "2  -37.8093    144.9944  Northern Metropolitan        4019.0   \n",
      "3  -37.7969    144.9969  Northern Metropolitan        4019.0   \n",
      "4  -37.8072    144.9941  Northern Metropolitan        4019.0   \n",
      "\n",
      "   Landsize_original  Price_original  Landsize_winsorized  Price_winsorized  \n",
      "0              202.0       1480000.0                202.0         1480000.0  \n",
      "1              156.0       1035000.0                156.0         1035000.0  \n",
      "2              134.0       1465000.0                134.0         1465000.0  \n",
      "3               94.0        850000.0                 94.0          850000.0  \n",
      "4              120.0       1600000.0                120.0         1600000.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Rename the Distance columns to meaningfull name\n",
    "sales_data.rename(columns={'Distance': 'Distance from CBD'}, inplace=True)\n",
    "\n",
    "print(sales_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price_winsorized  Landsize_winsorized  PricePerSquareMeter\n",
      "0         1480000.0                202.0          7326.732673\n",
      "1         1035000.0                156.0          6634.615385\n",
      "2         1465000.0                134.0         10932.835821\n",
      "3          850000.0                 94.0          9042.553191\n",
      "4         1600000.0                120.0         13333.333333\n"
     ]
    }
   ],
   "source": [
    "# create a new feautre for PricePerSquareMeter\n",
    "import numpy as np\n",
    "sales_data['PricePerSquareMeter'] = sales_data['Price'] / sales_data['Landsize']\n",
    "\n",
    "# Check the first few rows to verify the new feature\n",
    "print(sales_data[['Price_winsorized', 'Landsize_winsorized', 'PricePerSquareMeter']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Optional for model selection (Note!! On this)\n",
    "\n",
    "# # feature scaling is necessary because many \n",
    "# # machine learning algorithms perform better when numerical features are on the same scale\n",
    "# # The range is between 0.1 to 1\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# numerical_columns = ['Distance from CBD', 'Landsize_winsorized', 'Price_winsorized', 'PricePerSquareMeter']\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0.1, 1))\n",
    "\n",
    "# sales_data[numerical_columns] = scaler.fit_transform(sales_data[numerical_columns])\n",
    "\n",
    "# print(sales_data[numerical_columns].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a single column from the DataFrame\n",
    "sales_data.drop(columns=['Price'], inplace=True)\n",
    "sales_data.drop(columns=['Landsize'], inplace=True)\n",
    "sales_data.drop(columns=['Landsize_original'], inplace=True)\n",
    "sales_data.drop(columns=['Price_original'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Method', 'Date',\n",
      "       'Distance from CBD', 'Postcode', 'Bedroom2', 'Bathroom', 'CouncilArea',\n",
      "       'Lattitude', 'Longtitude', 'Regionname', 'Propertycount',\n",
      "       'Landsize_winsorized', 'Price_winsorized', 'PricePerSquareMeter'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#To check the final cleaned data columns\n",
    "\n",
    "print(sales_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We removed 238 properties with land sizes greater than 2000 sqm.\n"
     ]
    }
   ],
   "source": [
    "# I remove the landsize that exceeded 2000 sqm to remove the remaining outlier in Winsorized Landsize\n",
    "\n",
    "\n",
    "custom_threshold = 2000\n",
    "\n",
    "sales_data_clean = sales_data[sales_data['Landsize_winsorized'] <= custom_threshold]\n",
    "\n",
    "removed_rows = len(sales_data) - len(sales_data_clean)\n",
    "\n",
    "print(f\"We removed {removed_rows} properties with land sizes greater than {custom_threshold} sqm.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_clean.to_csv('/Users/mac/Desktop/Computing Innovation Project/Melbourne_DataSet/new_melb_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year ending                        0\n",
      "Local Government Area              0\n",
      "Output Year                        0\n",
      "Year ending.1                      0\n",
      "Latitude (generated)               0\n",
      "Longitude (generated)              0\n",
      "Alleged Offender Incident Rate     0\n",
      "Alleged Offender Incidents         0\n",
      "Criminial Incident Rate            0\n",
      "Family Incident Count             79\n",
      "Family Incident Rate              79\n",
      "Incidents Recorded                 0\n",
      "Offence Count                      0\n",
      "Offence Rate                       0\n",
      "Victim Reports                     0\n",
      "Victimisation Rate                 0\n",
      "dtype: int64\n",
      "Total number of rows: 79\n"
     ]
    }
   ],
   "source": [
    "# Loading and Identify the null value in Crime Melbourne 2016 data\n",
    "file_path_1 = '/Users/mac/Desktop/Computing Innovation Project/Melbourne_DataSet/crime_melbourne_2016.csv'\n",
    "\n",
    "criminal_rate_2016_data = pd.read_csv(file_path_1,encoding='utf-16',delimiter='\\t')\n",
    "\n",
    "missing_values1 = criminal_rate_2016_data.isnull().sum()\n",
    "print(missing_values1)\n",
    "\n",
    "row_count = len(criminal_rate_2016_data)\n",
    "print(f'Total number of rows: {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year ending                        0\n",
      "Local Government Area              0\n",
      "Output Year                        0\n",
      "Year ending.1                      0\n",
      "Latitude (generated)               0\n",
      "Longitude (generated)              0\n",
      "Alleged Offender Incident Rate     0\n",
      "Alleged Offender Incidents         0\n",
      "Criminial Incident Rate            0\n",
      "Family Incident Count             79\n",
      "Family Incident Rate              79\n",
      "Incidents Recorded                 0\n",
      "Offence Count                      0\n",
      "Offence Rate                       0\n",
      "Victim Reports                     0\n",
      "Victimisation Rate                 0\n",
      "dtype: int64\n",
      "Total number of rows: 79\n"
     ]
    }
   ],
   "source": [
    "# Loading and Identify the null value in Crime Melbourne 2017 data\n",
    "file_path_2 = '/Users/mac/Desktop/Computing Innovation Project/Melbourne_DataSet/crime_melbourne_2017.csv'\n",
    "\n",
    "criminal_rate_2017_data = pd.read_csv(file_path_2,encoding='utf-16',delimiter='\\t')\n",
    "\n",
    "missing_values2 = criminal_rate_2017_data.isnull().sum()\n",
    "print(missing_values2)\n",
    "\n",
    "row_count = len(criminal_rate_2016_data)\n",
    "print(f'Total number of rows: {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Year ending Local Government Area  Output Year Year ending.1  \\\n",
      "0       March          Yarriambiack         2016         March   \n",
      "1       March          Yarra Ranges         2016         March   \n",
      "2       March                 Yarra         2016         March   \n",
      "\n",
      "   Latitude (generated)  Longitude (generated) Alleged Offender Incident Rate  \\\n",
      "0              -35.9900               142.4191                        2,847.4   \n",
      "1              -37.7143               145.6968                        1,638.9   \n",
      "2              -37.8021               144.9985                        3,682.7   \n",
      "\n",
      "  Alleged Offender Incidents Criminial Incident Rate  Family Incident Count  \\\n",
      "0                        192                 4,908.8                    NaN   \n",
      "1                      2,544                 3,695.9                    NaN   \n",
      "2                      3,421                11,176.2                    NaN   \n",
      "\n",
      "   Family Incident Rate Incidents Recorded Offence Count Offence Rate  \\\n",
      "0                   NaN                331           485      7,192.6   \n",
      "1                   NaN              5,737         8,233      5,303.9   \n",
      "2                   NaN             10,382        13,363     14,385.2   \n",
      "\n",
      "  Victim Reports Victimisation Rate  \n",
      "0            213            3,158.8  \n",
      "1          3,189            2,054.4  \n",
      "2          6,337            6,821.8  \n"
     ]
    }
   ],
   "source": [
    "print(criminal_rate_2016_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Unnecessary Data of 2016 and 2017 Crime Dataset\n",
    "criminal_rate_2016_data.drop(columns=['Year ending'], inplace=True)\n",
    "criminal_rate_2016_data.drop(columns=['Alleged Offender Incident Rate'], inplace=True)\n",
    "criminal_rate_2016_data.drop(columns=['Alleged Offender Incidents'], inplace=True)\n",
    "criminal_rate_2016_data.drop(columns=['Family Incident Count'], inplace=True)\n",
    "criminal_rate_2016_data.drop(columns=['Family Incident Rate'], inplace=True)\n",
    "criminal_rate_2016_data.drop(columns=['Incidents Recorded'], inplace=True)\n",
    "criminal_rate_2016_data.drop(columns=['Offence Count'], inplace=True)\n",
    "criminal_rate_2016_data.drop(columns=['Offence Rate'], inplace=True)\n",
    "criminal_rate_2016_data.drop(columns=['Victim Reports'], inplace=True)\n",
    "\n",
    "criminal_rate_2017_data.drop(columns=['Year ending'], inplace=True)\n",
    "criminal_rate_2017_data.drop(columns=['Alleged Offender Incident Rate'], inplace=True)\n",
    "criminal_rate_2017_data.drop(columns=['Alleged Offender Incidents'], inplace=True)\n",
    "criminal_rate_2017_data.drop(columns=['Family Incident Count'], inplace=True)\n",
    "criminal_rate_2017_data.drop(columns=['Family Incident Rate'], inplace=True)\n",
    "criminal_rate_2017_data.drop(columns=['Incidents Recorded'], inplace=True)\n",
    "criminal_rate_2017_data.drop(columns=['Offence Count'], inplace=True)\n",
    "criminal_rate_2017_data.drop(columns=['Offence Rate'], inplace=True)\n",
    "criminal_rate_2017_data.drop(columns=['Victim Reports'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Local Government Area', 'Output Year', 'Year ending.1',\n",
      "       'Latitude (generated)', 'Longitude (generated)',\n",
      "       'Criminial Incident Rate', 'Victimisation Rate'],\n",
      "      dtype='object')\n",
      "Index(['Local Government Area', 'Output Year', 'Year ending.1',\n",
      "       'Latitude (generated)', 'Longitude (generated)',\n",
      "       'Criminial Incident Rate', 'Victimisation Rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(criminal_rate_2016_data.columns)\n",
    "print(criminal_rate_2017_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Local Government Area  Average_Criminial_Incidents_Rate  \\\n",
      "0          Yarriambiack                           4914.15   \n",
      "1          Yarra Ranges                           3901.30   \n",
      "2                 Yarra                          11571.00   \n",
      "3               Wyndham                           5108.35   \n",
      "4               Wodonga                           6300.90   \n",
      "\n",
      "   Average_Victimisation_Rate  \n",
      "0                     3107.45  \n",
      "1                     2140.50  \n",
      "2                     7086.95  \n",
      "3                     2994.75  \n",
      "4                     3521.65  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merging the Data of Criminial Incident Rate and Vicimisation Rate together and find the average\n",
    "merged_crime_data = pd.merge(criminal_rate_2016_data, criminal_rate_2017_data, on='Local Government Area', suffixes=('_2016', '_2017'))\n",
    "\n",
    "merged_crime_data['Criminial Incident Rate_2016'] = pd.to_numeric(merged_crime_data['Criminial Incident Rate_2016'].str.replace(',', ''), errors='coerce')\n",
    "merged_crime_data['Criminial Incident Rate_2017'] = pd.to_numeric(merged_crime_data['Criminial Incident Rate_2017'].str.replace(',', ''), errors='coerce')\n",
    "merged_crime_data['Victimisation Rate_2016'] = pd.to_numeric(merged_crime_data['Victimisation Rate_2016'].str.replace(',', ''), errors='coerce')\n",
    "merged_crime_data['Victimisation Rate_2017'] = pd.to_numeric(merged_crime_data['Victimisation Rate_2017'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "merged_crime_data['Average_Criminial_Incidents_Rate'] = (merged_crime_data['Criminial Incident Rate_2016'] + merged_crime_data['Criminial Incident Rate_2017']) / 2\n",
    "merged_crime_data['Average_Victimisation_Rate'] = (merged_crime_data['Victimisation Rate_2016'] + merged_crime_data['Victimisation Rate_2017']) / 2\n",
    "\n",
    "print(merged_crime_data[['Local Government Area', 'Average_Criminial_Incidents_Rate', 'Average_Victimisation_Rate']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/93nzx6zn4qq3tmg26cwcn91w0000gn/T/ipykernel_6622/1358529276.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_data_clean['PricePerSquareMeter'] = sales_data_clean['PricePerSquareMeter'].round(2)\n"
     ]
    }
   ],
   "source": [
    "# Round up the average rate to allow only 2 decimal \n",
    "merged_crime_data['Average_Criminial_Incidents_Rate'] = merged_crime_data['Average_Criminial_Incidents_Rate'].round(2)\n",
    "merged_crime_data['Average_Victimisation_Rate'] = merged_crime_data['Average_Victimisation_Rate'].round(2)\n",
    "\n",
    "sales_data_clean['PricePerSquareMeter'] = sales_data_clean['PricePerSquareMeter'].round(2)\n",
    "\n",
    "# Selected only the useful column\n",
    "clean_crime_data = merged_crime_data[['Local Government Area', 'Average_Criminial_Incidents_Rate', 'Average_Victimisation_Rate']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import it to a new file\n",
    "clean_crime_data.to_csv('/Users/mac/Desktop/Computing Innovation Project/Melbourne_DataSet/new_merge_crime_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file with 'unknown' values filtered out has been created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/93nzx6zn4qq3tmg26cwcn91w0000gn/T/ipykernel_6622/2989823445.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_data_clean['CouncilArea'] = sales_data_clean['CouncilArea'].str.strip().str.lower()\n",
      "/var/folders/lp/93nzx6zn4qq3tmg26cwcn91w0000gn/T/ipykernel_6622/2989823445.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_crime_data['Local Government Area'] = clean_crime_data['Local Government Area'].str.strip().str.lower()\n"
     ]
    }
   ],
   "source": [
    "# remove leading/trailing spaces in both columns and normolize the case\n",
    "sales_data_clean['CouncilArea'] = sales_data_clean['CouncilArea'].str.strip().str.lower()\n",
    "clean_crime_data['Local Government Area'] = clean_crime_data['Local Government Area'].str.strip().str.lower()\n",
    "\n",
    "# Remove rows with 'unknown' in the 'CouncilArea'\n",
    "sales_data_clean = sales_data_clean[sales_data_clean['CouncilArea'] != 'Unknown']\n",
    "\n",
    "# Merge the datasets using 'Local Government Area' as the primary key and 'CouncilArea' as the foreign key\n",
    "merged_data = pd.merge(sales_data_clean, \n",
    "                       clean_crime_data[['Local Government Area', 'Average_Criminial_Incidents_Rate', 'Average_Victimisation_Rate']], \n",
    "                       left_on='CouncilArea', \n",
    "                       right_on='Local Government Area', \n",
    "                       how='left')\n",
    "\n",
    "merged_data = merged_data.drop(columns=['Local Government Area'])\n",
    "\n",
    "# Import to the new file\n",
    "merged_data.to_csv('/Users/mac/Desktop/Computing Innovation Project/Melbourne_DataSet/official_clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
